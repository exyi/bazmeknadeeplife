{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7120083-c7f7-4fbc-a718-29ed1edefe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import muon as mu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mofax as mofa\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "from pyro.nn import PyroSample, PyroModule\n",
    "from pyro.infer import SVI, Trace_ELBO, autoguide\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import softplus\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import seaborn as sns\n",
    "import muon as mu\n",
    "import anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45e0d5bd-c307-4b4d-9b9d-ef46a02dc580",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"/scratch/deeplife/\"\n",
    "pbmc = sc.read_10x_h5(dir+\"5k_pbmc_protein_v3_nextgem_filtered_feature_bc_matrix.h5\", gex_only=False)\n",
    "pbmc.var_names_make_unique()\n",
    "pbmc.layers[\"counts\"] = pbmc.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c95a25a-bc4d-43ca-9a2e-bb4f45d1ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = pbmc[:, pbmc.var[\"feature_types\"] == \"Antibody Capture\"].copy()\n",
    "rna = pbmc[:, pbmc.var[\"feature_types\"] == \"Gene Expression\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd199ed8-4332-4c99-9ac9-e338f2d9ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FA(PyroModule):\n",
    "    def __init__(self, Y, K):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            Y: Tensor (Samples x Features)\n",
    "            K: Number of Latent Factors\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        pyro.clear_param_store()\n",
    "        \n",
    "        # data\n",
    "        self.Y = Y\n",
    "        self.K = K\n",
    "        \n",
    "        self.num_samples = self.Y.shape[0]\n",
    "        self.num_features = self.Y.shape[1]\n",
    "        \n",
    "        self.sample_plate = pyro.plate(\"sample\", self.num_samples)\n",
    "        self.feature_plate = pyro.plate(\"feature\", self.num_features)\n",
    "        self.latent_factor_plate = pyro.plate(\"latent factors\", self.K)\n",
    "        \n",
    "        \n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        how to generate a matrix\n",
    "        \"\"\"\n",
    "        with self.latent_factor_plate:\n",
    "            with self.feature_plate:\n",
    "                # sample weight matrix with Normal prior distribution\n",
    "                W = pyro.sample(\"W\", pyro.distributions.Normal(0., 1.))                \n",
    "                \n",
    "            with self.sample_plate:\n",
    "                # sample factor matrix with Normal prior distribution\n",
    "                Z = pyro.sample(\"Z\", pyro.distributions.Normal(0., 1.))\n",
    "        \n",
    "        # estimate for Y\n",
    "        Y_hat = torch.matmul(Z, W.t())\n",
    "        \n",
    "        with pyro.plate(\"feature_\", self.Y.shape[1]), pyro.plate(\"sample_\", self.Y.shape[0]):\n",
    "            # masking the NA values such that they are not considered in the distributions\n",
    "            obs_mask = torch.logical_not(torch.isnan(self.Y))\n",
    "            with pyro.poutine.mask(mask=obs_mask):\n",
    "                # a valid value for the NAs has to be defined even though these samples will be ignored later\n",
    "                self.Y = torch.nan_to_num(self.Y, nan=0) \n",
    "        \n",
    "                # sample scale parameter for each feature-sample pair with LogNormal prior (has to be positive)\n",
    "                scale = pyro.sample(\"scale\", pyro.distributions.LogNormal(0., 1.))\n",
    "                # compare sampled estimation to the true observation Y\n",
    "                pyro.sample(\"obs\", pyro.distributions.Normal(Y_hat, scale), obs=self.Y)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        # set training parameters\n",
    "        optimizer = pyro.optim.Adam({\"lr\": 0.02})\n",
    "        elbo = Trace_ELBO()\n",
    "        guide = autoguide.AutoDelta(self.model)\n",
    "        \n",
    "        # initialize stochastic variational inference\n",
    "        svi = SVI(\n",
    "            model = self.model,\n",
    "            guide = guide,\n",
    "            optim = optimizer,\n",
    "            loss = elbo\n",
    "        )\n",
    "        \n",
    "        num_iterations = 4000\n",
    "        train_loss = []\n",
    "        for j in range(num_iterations):\n",
    "            # calculate the loss and take a gradient step\n",
    "            loss = svi.step()\n",
    "\n",
    "            train_loss.append(loss/self.Y.shape[0])\n",
    "            if j % 200 == 0:\n",
    "                print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / self.Y.shape[0]))\n",
    "        \n",
    "        # Obtain maximum a posteriori estimates for W and Z\n",
    "        map_estimates = guide(self.Y)\n",
    "        \n",
    "        return train_loss, map_estimates, guide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f6cc962-3146-4083-8f9a-192c1ef15dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 2279998.1385\n",
      "[iteration 0201] loss: 87566.6773\n",
      "[iteration 0401] loss: 30587.6447\n",
      "[iteration 0601] loss: 15317.3306\n",
      "[iteration 0801] loss: 9143.7706\n",
      "[iteration 1001] loss: 6099.0164\n",
      "[iteration 1201] loss: 4400.4007\n",
      "[iteration 1401] loss: 3368.6171\n",
      "[iteration 1601] loss: 2695.5634\n",
      "[iteration 1801] loss: 2233.0764\n",
      "[iteration 2001] loss: 1901.8620\n",
      "[iteration 2201] loss: 1658.9542\n",
      "[iteration 2401] loss: 1476.1332\n",
      "[iteration 2601] loss: 1334.7491\n",
      "[iteration 2801] loss: 1223.7632\n",
      "[iteration 3001] loss: 1135.0665\n",
      "[iteration 3201] loss: 1062.6931\n",
      "[iteration 3401] loss: 1001.9166\n",
      "[iteration 3601] loss: 949.7983\n",
      "[iteration 3801] loss: 903.5972\n"
     ]
    }
   ],
   "source": [
    "factor_model = FA(Y = torch.tensor(protein.X.toarray()), K = 5)\n",
    "loss, map_estimates, trained_guide = factor_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b384fdc-4864-44e3-bffd-c7ca858d52a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deeplife2)",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
