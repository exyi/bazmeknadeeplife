{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7120083-c7f7-4fbc-a718-29ed1edefe09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/venvs/deeplife2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import muon as mu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mofax as mofa\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "from pyro.nn import PyroSample, PyroModule\n",
    "from pyro.infer import SVI, Trace_ELBO, autoguide\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import softplus\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import seaborn as sns\n",
    "import muon as mu\n",
    "import anndata\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def to_device(t): return torch.tensor(t).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e0d5bd-c307-4b4d-9b9d-ef46a02dc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/venvs/deeplife2/lib/python3.12/site-packages/anndata/_core/anndata.py:1820: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "dir=\"/scratch/deeplife/\"\n",
    "pbmc = sc.read_10x_h5(dir+\"5k_pbmc_protein_v3_nextgem_filtered_feature_bc_matrix.h5\", gex_only=False)\n",
    "pbmc.var_names_make_unique()\n",
    "pbmc.layers[\"counts\"] = pbmc.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c95a25a-bc4d-43ca-9a2e-bb4f45d1ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = pbmc[:, pbmc.var[\"feature_types\"] == \"Antibody Capture\"].copy()\n",
    "rna = pbmc[:, pbmc.var[\"feature_types\"] == \"Gene Expression\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd199ed8-4332-4c99-9ac9-e338f2d9ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FA(PyroModule):\n",
    "    def __init__(self, Y, K):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            Y: Tensor (Samples x Features)\n",
    "            K: Number of Latent Factors\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        pyro.clear_param_store()\n",
    "        \n",
    "        # data\n",
    "        self.obs_mask = torch.logical_not(torch.isnan(Y))\n",
    "        self.Y = torch.nan_to_num(Y, nan=0)\n",
    "        self.K = K\n",
    "        self.batch_size = 64\n",
    "        \n",
    "        self.num_samples = self.Y.shape[0]\n",
    "        self.num_features = self.Y.shape[1]\n",
    "        \n",
    "        self.sample_plate = pyro.plate(\"sample\", self.num_samples, subsample_size=self.batch_size)\n",
    "        self.feature_plate = pyro.plate(\"feature\", self.num_features)\n",
    "        self.latent_factor_plate = pyro.plate(\"latent factors\", self.K)\n",
    "        \n",
    "        \n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        how to generate a matrix\n",
    "        \"\"\"\n",
    "        with self.latent_factor_plate:\n",
    "            with self.feature_plate:\n",
    "                # sample weight matrix with Normal prior distribution\n",
    "                W = pyro.sample(\"W\", pyro.distributions.Normal(0., to_device(1.0)))                \n",
    "                \n",
    "            with self.sample_plate:\n",
    "                # sample factor matrix with Normal prior distribution\n",
    "                Z = pyro.sample(\"Z\", pyro.distributions.Normal(0., to_device(1.0)))\n",
    "        \n",
    "        # estimate for Y\n",
    "        Y_hat = torch.matmul(Z, W.t())\n",
    "        # print(Z.shape, W.shape, self.Y.shape, Y_hat.shape)\n",
    "        \n",
    "        with pyro.plate(\"feature_\", self.Y.shape[1]), pyro.plate(\"sample_\", self.Y.shape[0], subsample_size=self.batch_size) as sample_shit:\n",
    "            # print(sample_shit)\n",
    "            # masking the NA values such that they are not considered in the distributions\n",
    "            with pyro.poutine.mask(mask=self.obs_mask[sample_shit, :]):\n",
    "                # a valid value for the NAs has to be defined even though these samples will be ignored later\n",
    "        \n",
    "                # sample scale parameter for each feature-sample pair with LogNormal prior (has to be positive)\n",
    "                scale = pyro.sample(\"scale\", pyro.distributions.LogNormal(0., to_device(1.0)))\n",
    "                # compare sampled estimation to the true observation Y\n",
    "                pyro.sample(\"obs\", pyro.distributions.Normal(Y_hat, scale), obs=self.Y[sample_shit, :])\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        # set training parameters\n",
    "        optimizer = pyro.optim.Adam({\"lr\": 0.02})\n",
    "        elbo = Trace_ELBO()\n",
    "        guide = autoguide.AutoNormal(self.model)\n",
    "        \n",
    "        # initialize stochastic variational inference\n",
    "        svi = SVI(\n",
    "            model = self.model,\n",
    "            guide = guide,\n",
    "            optim = optimizer,\n",
    "            loss = elbo\n",
    "        )\n",
    "        \n",
    "        num_iterations = 4000\n",
    "        train_loss = []\n",
    "        for j in range(num_iterations):\n",
    "            # calculate the loss and take a gradient step\n",
    "            loss = svi.step()\n",
    "\n",
    "            train_loss.append(loss/self.Y.shape[0])\n",
    "            if j % 200 == 0:\n",
    "                print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / self.Y.shape[0]))\n",
    "        \n",
    "        # Obtain maximum a posteriori estimates for W and Z\n",
    "        map_estimates = guide(self.Y)\n",
    "        \n",
    "        return train_loss, map_estimates, guide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eca708-be5b-4f78-b659-c70bed94fdca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6cc962-3146-4083-8f9a-192c1ef15dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/venvs/deeplife2/lib/python3.12/site-packages/pyro/util.py:365: UserWarning: Found plate statements in guide but not model: {'sample', 'feature', 'latent factors'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 275462.8760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/venvs/deeplife2/lib/python3.12/site-packages/pyro/util.py:365: UserWarning: Found plate statements in guide but not model: {'sample', 'feature', 'latent factors'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0201] loss: 129847.1281\n",
      "[iteration 0401] loss: 91448.8441\n",
      "[iteration 0601] loss: 67855.4114\n",
      "[iteration 0801] loss: 50201.4829\n",
      "[iteration 1001] loss: 39054.9678\n",
      "[iteration 1201] loss: 32418.0226\n",
      "[iteration 1401] loss: 30279.5930\n",
      "[iteration 1601] loss: 30611.5712\n",
      "[iteration 1801] loss: 31037.8897\n",
      "[iteration 2001] loss: 32382.3728\n",
      "[iteration 2201] loss: 33839.2646\n",
      "[iteration 2401] loss: 37202.1101\n"
     ]
    }
   ],
   "source": [
    "factor_model = FA(Y = torch.tensor(rna.X.toarray()).to(device), K = 5)\n",
    "loss, map_estimates, trained_guide = factor_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d2985-f84d-4c06-9905-e70fba8c930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print({ k: v.shape for k, v in map_estimates.items() })\n",
    "print(trained_guide(factor_model.Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b384fdc-4864-44e3-bffd-c7ca858d52a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pyro.get_param_store().get_all_param_names())\n",
    "pyro.get_param_store().get_param(\"AutoNormal.locs.W\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deeplife2)",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
